{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahenoor22/skin-disease-build/blob/main/model_build/CNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fehlOQ9Ri8i"
      },
      "source": [
        "\r\n",
        "import os\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from glob import glob\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.utils.np_utils import to_categorical\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.callbacks import ReduceLROnPlateau\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten\r\n",
        "from keras.layers import Conv2D, MaxPooling2D\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from typing import Optional\r\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\r\n",
        "from PIL import Image\r\n",
        "!chmod 600 /content/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQzevlwHMOHx"
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR']='/content'\r\n",
        "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3qy_5-KMZv6"
      },
      "source": [
        "!unzip \\*.zip && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxZ1_VeWSgjC"
      },
      "source": [
        "train_dir = r\"/content/base_dir/base_dir/train_dir\"\r\n",
        "test_dir=r\"/content/base_dir/base_dir/val_dir\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa7D5ihxrpjn"
      },
      "source": [
        "data = pd.read_csv('/content/hmnist_28_28_RGB.csv')\r\n",
        "\r\n",
        "X = data.drop(columns='label')/255\r\n",
        "Y = data['label']\r\n",
        "\r\n",
        "num_rows, num_cols = 28, 28\r\n",
        "num_classes = len(set(Y))\r\n",
        "\r\n",
        "X = np.array(X)\r\n",
        "X = X.reshape(X.shape[0], num_rows, num_cols, 3)\r\n",
        "\r\n",
        "Y = np.eye(num_classes)[np.array(Y.astype(int)).reshape(-1)]\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\r\n",
        "#Split the dataset into 80% training and 20% test\r\n",
        "\r\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pw0dDuWSz1_"
      },
      "source": [
        "base_skin_dir = os.path.join('..', '/content')\r\n",
        "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\r\n",
        "                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\r\n",
        "\r\n",
        "lesion_type_dict = {\r\n",
        "    'nv': 'Melanocytic nevi',\r\n",
        "    'mel': 'Melanoma',\r\n",
        "    'bkl': 'Benign keratosis-like lesions ',\r\n",
        "    'bcc': 'Basal cell carcinoma',\r\n",
        "    'akiec': 'Actinic keratoses',\r\n",
        "    'vasc': 'Vascular lesions',\r\n",
        "    'df': 'Dermatofibroma'\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmh48_5lqut8"
      },
      "source": [
        "skin_data = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\r\n",
        "skin_data['path'] = skin_data['image_id'].map(imageid_path_dict.get)\r\n",
        "skin_data['cell_type'] = skin_data['dx'].map(lesion_type_dict.get) \r\n",
        "skin_data['cell_type_idx'] = pd.Categorical(skin_data['cell_type']).codes\r\n",
        "skin_data.sample(3)\r\n",
        "skin_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5yHopy_-vhp"
      },
      "source": [
        "skin_data['age'].fillna((skin_data['age'].mean()), inplace=True)\r\n",
        "#Replace null age with mean age\r\n",
        "\r\n",
        "skin_data['image'] = skin_data['path'].map(lambda x: np.asarray(Image.open(x).resize((28,28))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVOQ61TKq6ZC"
      },
      "source": [
        "\r\n",
        "n_samples = 5\r\n",
        "fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\r\n",
        "for n_axs, (type_name, type_rows) in zip(m_axs, \r\n",
        "                                         skin_data.sort_values(['cell_type']).groupby('cell_type')):\r\n",
        "    n_axs[0].set_title(type_name)\r\n",
        "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=6542).iterrows()):\r\n",
        "        c_ax.imshow(c_row['image'])\r\n",
        "        c_ax.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyXsgwMe_mh4"
      },
      "source": [
        "skin_data['image'].map(lambda x: x.shape).value_counts()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtiIZv-eTCsu"
      },
      "source": [
        "input_shape = (28, 28, 3)\r\n",
        "num_classes = 7\r\n",
        "model = Sequential([\r\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape=input_shape),\r\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\r\n",
        "    MaxPooling2D(),\r\n",
        "    Dropout(0.25),\r\n",
        "\r\n",
        "    Conv2D(64, 3, padding='same', activation='relu', input_shape=input_shape),\r\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\r\n",
        "    MaxPooling2D(),\r\n",
        "    Dropout(0.4),\r\n",
        "    \r\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\r\n",
        "    MaxPooling2D(),\r\n",
        "    Dropout(0.5),\r\n",
        "    \r\n",
        "    Flatten(),\r\n",
        "    Dense(512, activation='relu'),\r\n",
        "    Dropout(0.55),\r\n",
        "    Dense(7, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \r\n",
        "                                            patience=3, \r\n",
        "                                            verbose=1, \r\n",
        "                                            factor=0.5, \r\n",
        "                                            min_lr=0.00001)\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otLL0nRuS4Es"
      },
      "source": [
        "datagen = ImageDataGenerator(\r\n",
        "        featurewise_center=False,  \r\n",
        "        samplewise_center=False,  \r\n",
        "        featurewise_std_normalization=False,  \r\n",
        "        samplewise_std_normalization=False,  \r\n",
        "        zca_whitening=False,  \r\n",
        "        rotation_range=10,  \r\n",
        "        zoom_range = 0.1,\r\n",
        "        width_shift_range=0.1,  \r\n",
        "        height_shift_range=0.1,  \r\n",
        "        horizontal_flip=False,  \r\n",
        "        vertical_flip=False)  \r\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i2NB7hHTJad"
      },
      "source": [
        "\r\n",
        "epochs = 30\r\n",
        "batch_size = 100\r\n",
        "history = model.fit_generator(\r\n",
        "    datagen.flow(X_train,y_train, batch_size=batch_size),\r\n",
        "    steps_per_epoch=X_train.shape[0] // batch_size,\r\n",
        "    epochs=epochs,\r\n",
        "    validation_data=(X_validate,y_validate),\r\n",
        "    validation_steps=X_validate.shape[0] // batch_size\r\n",
        "    ,callbacks=[learning_rate_reduction]\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1fP0UNbu_vB"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\r\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZq5pn1IIu6p"
      },
      "source": [
        "## **SAVE AND LOAD MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEBPwztSLBbI"
      },
      "source": [
        "if os.path.isfile('/content/model_build/CNN_model.h5') is False:\r\n",
        "  model.save('model_build/CNN_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OoanW4OH3I1"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "new_model=load_model(\"model_build/CNN_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qekCs8ETIKeK"
      },
      "source": [
        "new_model.summary()\r\n",
        "new_model.get_weights()\r\n",
        "new_model.optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX5WKKOeIri3"
      },
      "source": [
        "## **MODEL to Json**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X2s50NNIrAf"
      },
      "source": [
        "#save as JSON\r\n",
        "json_string=model.to_json()\r\n",
        "\r\n",
        "json_string\r\n",
        "from tensorflow.keras.models import model_from_json\r\n",
        "model_arch=model_from_json(json_string)\r\n",
        "model_arch.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "MR9OfF81I8yM",
        "outputId": "207eecfa-5b94-44b0-d589-3a9f585bfabe"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.preprocessing import image\r\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\r\n",
        "# img_width, img_height = 28,28\r\n",
        "# img = image.load_img('/content/ISIC_0026993.jpg', target_size = (img_width, img_height))\r\n",
        "# img = image.img_to_array(img)\r\n",
        "# img = np.expand_dims(img, axis = 0)\r\n",
        "# pred=model.predict_classes(img)\r\n",
        "\r\n",
        "# pred = lesion_type_dict[\"label_names\"][np.argmax(pred)]\r\n",
        "\r\n",
        "image_path=\"/content/ISIC_0026993.jpg\"\r\n",
        "img = image.load_img(image_path, target_size=(28,28))\r\n",
        "plt.imshow(img)\r\n",
        "img = np.expand_dims(img, axis=0)\r\n",
        "result=model.predict_classes(img)\r\n",
        "print(decode_predictions(result, top=3)[0])\r\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-88825819d7c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top)\u001b[0m\n\u001b[1;32m    525\u001b[0m               'keras.applications.resnet.decode_predictions')\n\u001b[1;32m    526\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top)\u001b[0m\n\u001b[1;32m    149\u001b[0m                      \u001b[0;34m'a batch of predictions '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                      \u001b[0;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                      'Found array with shape: ' + str(preds.shape))\n\u001b[0m\u001b[1;32m    152\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mCLASS_INDEX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     fpath = data_utils.get_file(\n",
            "\u001b[0;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFYO5o2Q1geE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}